{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graphic-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-despite",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "injured-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_content(path):\n",
    "    content = dict()\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            item = line.split(',{')\n",
    "            itemId = item[0]\n",
    "            data = json.loads('{' + item[1])\n",
    "\n",
    "            content[itemId] = data.get('Year', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Title', '') + ';;'\n",
    "            content[itemId] += data.get('Rated', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Released', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Director', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Genre', '') + ';;'\n",
    "            content[itemId] += data.get('Runtime', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Writer', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Actors', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Language', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Awards', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Poster', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Metascore', '').replace(' ', '') + ';;'\n",
    "            content[itemId] += data.get('Country', '') + ';;'\n",
    "            content[itemId] += data.get('imdbRating', '') + ';;'\n",
    "            content[itemId] += data.get('Type', '') + ';;'\n",
    "            content[itemId] += data.get('Plot', '')\n",
    "    df = pd.DataFrame(content, index=[0]).transpose()\n",
    "    df['itemId'] = df.index\n",
    "    df = pd.concat([df, df[0].str.split(';;', expand=True)], axis=1, ignore_index=True)\n",
    "    df = df.drop([0,1], axis=1)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['itemId','Year','Title','Rated','Released','Director','Genre','Runtime','Writer','Actors',\n",
    "                  'Language','Awards','Poster','Metascore','Country','imdbRating','Type','Plot']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alleged-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "targets = pd.read_csv('./data/targets.csv')\n",
    "content = read_content('./data/content.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "robust-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate first column\n",
    "sep = ratings['UserId:ItemId'].str.split(':', expand=True)\n",
    "sep.columns = ['UserId', 'ItemId']\n",
    "ratings = pd.concat([ratings, sep], axis=1)\n",
    "# selete columns\n",
    "ratings = ratings.drop(['UserId:ItemId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worthy-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate first column\n",
    "sep = targets['UserId:ItemId'].str.split(':', expand=True)\n",
    "sep.columns = ['UserId', 'ItemId']\n",
    "targets = pd.concat([targets, sep], axis=1)\n",
    "# selete columns\n",
    "targets = targets.drop(['UserId:ItemId'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-workstation",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demonstrated-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(content):\n",
    "    \"\"\"\n",
    "    FEATURE ENGINEER PROCESS\n",
    "    \n",
    "    promotes an extraction of features among those available in the dataset 'content.csv'\n",
    "    \"\"\"\n",
    "    ln = content.shape[0]\n",
    "    content = content.replace(['N/A', ''], 0)\n",
    "\n",
    "    # -- Year\n",
    "    content['Year'] = pd.to_numeric(content['Year'], downcast='integer')\n",
    "\n",
    "    # -- Rated\n",
    "    rated = pd.get_dummies(content['Rated'], prefix='Rated')\n",
    "    content = pd.concat([content, rated], axis=1)\n",
    "\n",
    "    # -- Released\n",
    "    content['Released_year'] = 0\n",
    "    content['Released_month'] = 0\n",
    "    content['Released_day'] = 0\n",
    "    for i in range(ln):\n",
    "        date = str(content['Released'][i])\n",
    "        if (date!='0'):\n",
    "            prs = parse(date)\n",
    "            content.loc[i, 'Released_year'] = prs.year\n",
    "            content.loc[i, 'Released_month'] = prs.month\n",
    "            content.loc[i, 'Released_day'] = prs.day\n",
    "\n",
    "    # -- Runtime\n",
    "    content['Runtime_min'] = 0\n",
    "    content['Runtime_hour'] = 0\n",
    "    for i in range(ln):\n",
    "        runtime = str(content['Runtime'][i])\n",
    "        if (runtime!='0'):\n",
    "            runtime = runtime.split('h')\n",
    "            if len(runtime)>1:\n",
    "                content.loc[i, 'Runtime_min'] = int(runtime[1][:(len(runtime[1])-3)])\n",
    "                content.loc[i, 'Runtime_hour'] = int(runtime[0])\n",
    "            else:\n",
    "                tm = int(runtime[0][:(len(runtime[0])-3)])\n",
    "                minutes = tm%60\n",
    "                hour = (tm-minutes)/60\n",
    "                content.loc[i, 'Runtime_min'] = minutes\n",
    "                content.loc[i, 'Runtime_hour'] = hour\n",
    "\n",
    "    # -- Languages\n",
    "    for i in range(ln):\n",
    "        cont = content['Language'][i]\n",
    "        if cont=='English':\n",
    "            content.loc[i, 'Language'] = 1\n",
    "        elif cont=='French':\n",
    "            content.loc[i, 'Language'] = 2\n",
    "        elif cont=='Japanese':\n",
    "            content.loc[i, 'Language'] = 3\n",
    "        elif cont=='Spanish':\n",
    "            content.loc[i, 'Language'] = 4\n",
    "        else:\n",
    "            content.loc[i, 'Language'] = 0\n",
    "    content['Language'] = pd.to_numeric(content['Language'], downcast='integer')\n",
    "\n",
    "    # -- Metascore\n",
    "    content['Metascore'] = pd.to_numeric(content['Metascore'], downcast='integer')\n",
    "\n",
    "    # -- Country\n",
    "    for i in range(ln):\n",
    "        cont = content['Country'][i]\n",
    "        if cont=='USA':\n",
    "            content.loc[i, 'Country'] = 1\n",
    "        elif cont=='UK':\n",
    "            content.loc[i, 'Country'] = 2\n",
    "        elif cont=='India':\n",
    "            content.loc[i, 'Country'] = 3\n",
    "        elif cont=='Japan':\n",
    "            content.loc[i, 'Country'] = 4\n",
    "        else:\n",
    "            content.loc[i, 'Country'] = 0\n",
    "    content['Country'] = pd.to_numeric(content['Country'], downcast='integer')\n",
    "\n",
    "    # -- imdbRating\n",
    "    content['imdbRating'] = pd.to_numeric(content['imdbRating'], downcast='integer')\n",
    "\n",
    "    # -- Type\n",
    "    content['Type'] = content['Type'].replace(['movie'], 1)\n",
    "    content['Type'] = content['Type'].replace(['episode'], 2)\n",
    "    content['Type'] = content['Type'].replace(['series'], 3)\n",
    "    \n",
    "    # --  Combining remaining categorical features\n",
    "    for i in range(ln):\n",
    "        content.loc[i, 'combinedFeatures'] = str(content['Genre'][i]) + ' ' +  str(content['Actors'][i])\n",
    "    \n",
    "    # -- Dropping columns\n",
    "    content = content.drop(['Rated', 'Released', 'Runtime', 'Awards', 'Poster', 'Title',\n",
    "                            'Director', 'Genre', 'Writer', 'Actors', 'Plot'], axis=1)\n",
    "    \n",
    "    return content\n",
    "\n",
    "content = feature_extraction(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-devil",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interior-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    def __init__(self, content, lenght):\n",
    "        data = [[(word.replace(',', '').replace('.', '').replace('(' , '').replace(')', ''))\n",
    "                     for word in row.lower().split()]\n",
    "                     for row in content['combinedFeatures']]\n",
    "        self.data_len = len(data)\n",
    "        \n",
    "        tfDict = []\n",
    "        for row in data:\n",
    "            tfDict.append(self.computeReviewTFDict(row))\n",
    "            \n",
    "        #Stores the review count dictionary\n",
    "        countDict = self.computeCountDict(tfDict)\n",
    "        \n",
    "        #Stores the idf dictionary\n",
    "        self.idfDict = self.computeIDFDict(countDict)\n",
    "            \n",
    "        tfidfDict = self.computeReviewTFIDFDict( self.computeIDFDict( self.computeCountDict(tfDict) ) )\n",
    "        \n",
    "        #Stores the TF-IDF dictionaries\n",
    "        tfidfDict = [self.computeReviewTFIDFDict(review) for review in tfDict]\n",
    "        \n",
    "        wordDict = sorted(countDict.keys())\n",
    "        del self.data_len,self.idfDict\n",
    "        self.tfidfVector = [self.computeTFIDFVector(review, wordDict)[:lenght] for review in tfidfDict]\n",
    "    \n",
    "    def computeReviewTFDict(self, review):\n",
    "        \"\"\" Returns a tf dictionary for each review whose keys are all\n",
    "        the unique words in the review and whose values are their\n",
    "        corresponding tf.\n",
    "        \"\"\"\n",
    "        # Counts the number of times the word appears in review\n",
    "        reviewTFDict = {}\n",
    "        for word in review:\n",
    "            if word in reviewTFDict:\n",
    "                reviewTFDict[word] += 1\n",
    "            else:\n",
    "                reviewTFDict[word] = 1\n",
    "        # Computes tf for each word\n",
    "        for word in reviewTFDict:\n",
    "            reviewTFDict[word] = reviewTFDict[word] / len(review)\n",
    "        return reviewTFDict\n",
    "\n",
    "    def computeCountDict(self, tfDict):\n",
    "        \"\"\" Returns a dictionary whose keys are all the unique words in\n",
    "        the dataset and whose values count the number of reviews in which\n",
    "        the word appears.\n",
    "        \"\"\"\n",
    "        countDict = {}\n",
    "        # Run through each review's tf dictionary and increment countDict's (word, doc) pair\n",
    "        for review in tfDict:\n",
    "            for word in review:\n",
    "                if word in countDict:\n",
    "                    countDict[word] += 1\n",
    "                else:\n",
    "                    countDict[word] = 1\n",
    "        return countDict\n",
    "\n",
    "    def computeIDFDict(self, countDict):\n",
    "        \"\"\" Returns a dictionary whose keys are all the unique words in the\n",
    "        dataset and whose values are their corresponding idf.\n",
    "        \"\"\"\n",
    "        idfDict = {}\n",
    "        for word in countDict:\n",
    "            idfDict[word] = log(self.data_len / countDict[word])\n",
    "        return idfDict\n",
    "\n",
    "    def computeReviewTFIDFDict(self, reviewTFDict):\n",
    "        \"\"\" Returns a dictionary whose keys are all the unique words in the\n",
    "        review and whose values are their corresponding tfidf.\n",
    "        \"\"\"\n",
    "        reviewTFIDFDict = {}\n",
    "        #For each word in the review, we multiply its tf and its idf.\n",
    "        for word in reviewTFDict:\n",
    "            reviewTFIDFDict[word] = reviewTFDict[word] * self.idfDict[word]\n",
    "        return reviewTFIDFDict\n",
    "\n",
    "    def computeTFIDFVector(self, review, wordDict):\n",
    "        tfidfVector = [0.0] * len(wordDict)\n",
    "\n",
    "        # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "        for i, word in enumerate(wordDict):\n",
    "           if word in review:\n",
    "                tfidfVector[i] = review[word]\n",
    "        return tfidfVector\n",
    "    \n",
    "    def get_TFIDFVector(self):\n",
    "        return self.tfidfVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVector = TfIdf(content, lenght=2000).get_TFIDFVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unique-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "content.index = content['itemId']\n",
    "content = content.drop(['itemId', 'combinedFeatures'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distributed-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVector = np.concatenate((content.values,tfidfVector), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-negative",
   "metadata": {},
   "source": [
    "### Users/items vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reasonable-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1362062307</td>\n",
       "      <td>u0026762</td>\n",
       "      <td>i2171847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1362062624</td>\n",
       "      <td>u0026502</td>\n",
       "      <td>i0444778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1362062838</td>\n",
       "      <td>u0004598</td>\n",
       "      <td>i1411238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1362063503</td>\n",
       "      <td>u0031317</td>\n",
       "      <td>i1496422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1362063653</td>\n",
       "      <td>u0024257</td>\n",
       "      <td>i0118799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction   Timestamp    UserId    ItemId\n",
       "0           6  1362062307  u0026762  i2171847\n",
       "1           8  1362062624  u0026502  i0444778\n",
       "2           6  1362062838  u0004598  i1411238\n",
       "3           7  1362063503  u0031317  i1496422\n",
       "4           5  1362063653  u0024257  i0118799"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "awful-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of items vectors\n",
    "itemsDict = dict()\n",
    "i = 0\n",
    "for itemID in content.index:\n",
    "    itemsDict[itemID] = tfidfVector[i]\n",
    "    i += 1\n",
    "\n",
    "# dict of items classified by each user\n",
    "userItems = dict()\n",
    "i = 0\n",
    "for userID in ratings['UserId']:\n",
    "    if userID in userItems:\n",
    "        if ratings['ItemId'][i] not in userItems[userID]:\n",
    "            userItems[userID].append([ratings['ItemId'][i], ratings['Prediction'][i]])\n",
    "    else:\n",
    "        userItems[userID] = [[ratings['ItemId'][i], ratings['Prediction'][i]]]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-completion",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amended-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarityPredict:\n",
    "    \"\"\"\n",
    "    Prediction of item scores from user id and item\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, itemsDict):\n",
    "        self.similarities = dict()\n",
    "        self.norms = dict()\n",
    "        for key in itemsDict.keys():\n",
    "            self.norms[key] = np.linalg.norm(itemsDict[key])\n",
    "    \n",
    "    def predict(self, userID, itemID):\n",
    "        num = 0\n",
    "        div = 0\n",
    "        if userID not in userItems:\n",
    "            return 7\n",
    "        for item in userItems[userID]:\n",
    "            st = itemID + item[0]\n",
    "            if st not in self.similarities:\n",
    "                s1 = set(itemsDict[itemID])\n",
    "                s2 = itemsDict[item[0]]\n",
    "                self.similarities[st] =  (np.dot(itemsDict[itemID],itemsDict[item[0]]) / (self.norms[itemID]*self.norms[item[0]])) #float(len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "            num += self.similarities[st] * item[1]\n",
    "            div += self.similarities[st]\n",
    "        return num/div\n",
    "\n",
    "cs = CosineSimilarityPredict(itemsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-negative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.write('UserId:ItemId,Prediction\\n')\n",
    "for i in targets.index:\n",
    "    userID = targets['UserId'][i]\n",
    "    itemID = targets['ItemId'][i]\n",
    "    sys.stdout.write(userID)\n",
    "    sys.stdout.write(':')\n",
    "    sys.stdout.write(itemID)\n",
    "    sys.stdout.write(',')\n",
    "    sys.stdout.write(str(cs.predict(userID, itemID)))\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "instant-mission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:01:40.56\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elementary-stanford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.296172535880619"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ratings['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-relations",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
